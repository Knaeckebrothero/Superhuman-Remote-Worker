# =============================================================================
# Graph-RAG Autonomous Agent System - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values

# =============================================================================
# Database Configuration
# =============================================================================

# Neo4j Database (Knowledge Graph)
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password_here

# PostgreSQL Database (Shared State / Job Tracking)
# Required for the two-agent system
DATABASE_URL=postgresql://graphrag:password@localhost:5432/graphrag

# Optional: Individual PostgreSQL connection parameters (if not using DATABASE_URL)
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5432
# POSTGRES_USER=graphrag
# POSTGRES_PASSWORD=password
# POSTGRES_DB=graphrag

# Optional: MongoDB for LLM request archiving
# MONGODB_URL=mongodb://localhost:27017/graphrag_logs

# =============================================================================
# LLM Configuration
# =============================================================================

# OpenAI API Key (or compatible API)
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Custom OpenAI-compatible API endpoint (e.g., vLLM, Ollama, llama.cpp)
# Leave unset to use OpenAI's API directly
# LLM_BASE_URL=http://your-server:8000/v1

# Optional: Alternative LLM Providers
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# COHERE_API_KEY=your_cohere_api_key_here

# =============================================================================
# Citation Engine Configuration
# =============================================================================

# Citation Engine database (can share with main DATABASE_URL)
CITATION_DB_URL=postgresql://graphrag:password@localhost:5432/graphrag

# Citation Engine LLM endpoint
CITATION_LLM_URL=http://localhost:8080/v1
CITATION_LLM_MODEL=gpt-oss-120b

# Reasoning level: low, medium, high
CITATION_REASONING_REQUIRED=low

# =============================================================================
# External Services
# =============================================================================

# Web Search (Tavily) - Required for Creator Agent research
# Get your API key at https://tavily.com/
TAVILY_API_KEY=your_tavily_api_key_here

# =============================================================================
# Agent Configuration
# =============================================================================

# Polling intervals (in seconds)
CREATOR_POLLING_INTERVAL=30
VALIDATOR_POLLING_INTERVAL=10

# Retry limits
MAX_REQUIREMENT_RETRIES=5

# =============================================================================
# Workflow Configuration (Legacy - for Streamlit UI)
# =============================================================================

# CSV Requirements File Path
CSV_FILE_PATH=data/requirements.csv

# WORKFLOW_MODE: "chain" for simple workflow or "agent" for LangGraph agent
# - chain: Linear workflow (refine -> query -> analyze) - faster, simpler
# - agent: Iterative agent (plan -> query -> reason -> repeat) - more thorough
WORKFLOW_MODE=agent

# =============================================================================
# Observability
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# =============================================================================
# Notes
# =============================================================================
# LLM model settings (model name, temperature, max_iterations, reasoning_level)
# are configured in config/llm_config.json - not in environment variables.
#
# Agent-specific settings (polling intervals, thresholds) are also in
# config/llm_config.json under creator_agent, validator_agent, and orchestrator.
