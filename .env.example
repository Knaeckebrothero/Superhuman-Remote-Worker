# =============================================================================
# Graph-RAG Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values

# =============================================================================
# Required: LLM Configuration
# =============================================================================

# OpenAI API Key (or compatible API)
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Custom OpenAI-compatible endpoint (vLLM, Ollama, llama.cpp)
# Leave unset to use OpenAI's API directly
# LLM_BASE_URL=http://your-server:8000/v1

# =============================================================================
# Required: PostgreSQL Database
# =============================================================================

# Connection URL (preferred)
DATABASE_URL=postgresql://graphrag:graphrag_password@localhost:5432/graphrag

# Or individual parameters (used if DATABASE_URL not set)
# POSTGRES_HOST=localhost
# POSTGRES_USER=graphrag
# POSTGRES_PASSWORD=graphrag_password
# POSTGRES_DB=graphrag

# =============================================================================
# Optional: Additional Services
# =============================================================================

# Neo4j (Knowledge Graph) - only if connections.neo4j: true in config
# NEO4J_URI=bolt://localhost:7687
# NEO4J_USERNAME=neo4j
# NEO4J_PASSWORD=neo4j_password

# MongoDB (LLM request archiving) - enables audit trail
# MONGODB_URL=mongodb://localhost:27017/graphrag_logs

# Tavily (Web Search) - required for web_search tool
# TAVILY_API_KEY=your_tavily_api_key_here

# Anthropic (Claude models) - required when using claude-* models
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google (Gemini models) - required when using gemini-* models
# GOOGLE_API_KEY=your_google_api_key_here

# Groq (Fast inference) - required when provider: groq
# GROQ_API_KEY=your_groq_api_key_here

# =============================================================================
# Optional: Orchestrator Configuration
# =============================================================================

# Orchestrator URL (default: http://localhost:8085)
# ORCHESTRATOR_URL=http://localhost:8085

# Agent identification (auto-detected if not set)
# AGENT_POD_IP=10.0.0.5
# AGENT_POD_PORT=8001
# AGENT_HOSTNAME=agent-pod-1

# Agent config to load (default: creator)
# AGENT_CONFIG=creator

# =============================================================================
# Optional: Workspace
# =============================================================================

# Base path for job workspaces (default: ./workspace)
# WORKSPACE_PATH=./workspace

# =============================================================================
# Optional: Citation Engine
# =============================================================================

# Citation database (defaults to DATABASE_URL)
# CITATION_DB_URL=postgresql://graphrag:graphrag_password@localhost:5432/graphrag

# Citation LLM endpoint (defaults to LLM_BASE_URL)
# CITATION_LLM_URL=http://localhost:8080/v1
# CITATION_LLM_MODEL=gpt-4
# Reasoning level also controls analysis depth
# CITATION_REASONING_REQUIRED=low

# =============================================================================
# Optional: Service Ports (for docker-compose)
# =============================================================================

# Override default ports if needed
# POSTGRES_PORT=5432
# NEO4J_BOLT_PORT=7687
# NEO4J_HTTP_PORT=7474
# MONGODB_PORT=27017
# ORCHESTRATOR_PORT=8085
# COCKPIT_PORT=4000
# AGENT_PORT=8001
# MCP_PORT=8000

# =============================================================================
# Optional: Logging & Debugging
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)
# LOG_LEVEL=INFO

# Stream LLM tokens to stderr (useful for debugging)
# DEBUG_LLM_STREAM=1
# DEBUG_LLM_TAIL=500
