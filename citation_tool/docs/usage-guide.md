# Usage Guide

This guide covers all features of the Citation Engine with practical examples.

## Table of Contents

- [Core Concepts](#core-concepts)
- [Source Types](#source-types)
  - [Document Sources](#document-sources)
  - [Web Sources](#web-sources)
  - [Database Sources](#database-sources)
  - [Custom Sources](#custom-sources)
- [Creating Citations](#creating-citations)
- [Verification](#verification)
- [Citation Formatting](#citation-formatting)
- [Working with Citations](#working-with-citations)
- [Multi-Agent Mode](#multi-agent-mode)
- [LangChain Integration](#langchain-integration)
- [Error Handling](#error-handling)

---

## Core Concepts

### The Citation Workflow

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│  Register       │     │  Create         │     │  Use            │
│  Source         │────▶│  Citation       │────▶│  Citation       │
│                 │     │                 │     │                 │
│  add_*_source() │     │  cite_*()       │     │  format_*()     │
└─────────────────┘     └─────────────────┘     └─────────────────┘
        │                       │
        ▼                       ▼
   Content extracted      LLM verifies quote
   and hashed             supports claim
```

### Key Principles

1. **Sources First**: Always register sources before citing them
2. **Explicit Quotes**: Every citation requires quote context from the source
3. **Verification**: Citations are verified by LLM before being marked valid
4. **Immutability**: Citations are append-only; corrections use `supersedes`

---

## Source Types

### Document Sources

For PDFs, text files, markdown, and JSON documents.

```python
from citation_engine import CitationEngine

with CitationEngine() as engine:

    # PDF document (requires [pdf] extra)
    pdf_source = engine.add_doc_source(
        file_path="research/paper.pdf",
        name="Smith et al. 2024",
        version="v2.1",
        metadata={
            "authors": ["Smith, J.", "Doe, A."],
            "doi": "10.1234/example.2024",
            "published": "2024-03-15"
        }
    )

    # Text file
    txt_source = engine.add_doc_source(
        file_path="docs/requirements.txt",
        name="System Requirements",
        version="1.0"
    )

    # Markdown file
    md_source = engine.add_doc_source(
        file_path="README.md",
        name="Project Documentation"
    )

    # JSON document
    json_source = engine.add_doc_source(
        file_path="config/schema.json",
        name="API Schema Definition"
    )
```

**Supported formats**: `.pdf`, `.txt`, `.md`, `.json`

**What gets stored**:
- Extracted text content
- SHA-256 content hash
- Original file path
- Custom metadata

### Web Sources

For web pages, archived at registration time (requires `[web]` extra).

```python
with CitationEngine() as engine:

    # Basic web source
    web_source = engine.add_web_source(
        url="https://docs.python.org/3/library/typing.html",
        name="Python Typing Documentation"
    )

    # With metadata
    news_source = engine.add_web_source(
        url="https://example.com/news/article",
        name="Industry Report 2024",
        version="2024-01-15",  # Access date as version
        metadata={
            "author": "Jane Reporter",
            "publication": "Tech News Daily"
        }
    )

    # The content is archived at registration
    print(f"Archived {len(web_source.content)} characters")
    print(f"Accessed: {web_source.metadata['accessed_at']}")
```

**What gets stored**:
- Extracted text (scripts/styles removed)
- Page title (if available)
- Access timestamp
- Content hash

### Database Sources

For query results and structured data.

```python
with CitationEngine() as engine:

    # SQL query result
    db_source = engine.add_db_source(
        identifier="analytics.user_growth_2024",
        name="User Growth Analysis",
        content="""
        Query: SELECT month, new_users, churn_rate FROM growth_metrics WHERE year = 2024

        Results:
        | month | new_users | churn_rate |
        |-------|-----------|------------|
        | Jan   | 15,234    | 2.1%       |
        | Feb   | 18,445    | 1.9%       |
        | Mar   | 22,891    | 1.7%       |
        """,
        query="SELECT month, new_users, churn_rate FROM growth_metrics WHERE year = 2024",
        metadata={
            "database": "analytics_prod",
            "executed_at": "2024-04-01T10:30:00Z"
        }
    )
```

**Use cases**:
- SQL query results
- API response data
- Aggregated statistics

### Custom Sources

For AI-generated content, analyses, or computed artifacts.

```python
with CitationEngine() as engine:

    # Analysis matrix generated by AI
    analysis_source = engine.add_custom_source(
        name="Competitive Analysis Matrix",
        content="""
        Competitive Analysis - Generated 2024-04-15

        | Feature        | Us  | Competitor A | Competitor B |
        |----------------|-----|--------------|--------------|
        | Price          | $$  | $$$          | $            |
        | Performance    | 9/10| 7/10         | 6/10         |
        | Support        | 24/7| Business hrs | Email only   |

        Summary: We offer the best value proposition with
        mid-range pricing and superior performance.
        """,
        description="AI-generated competitive analysis",
        metadata={
            "generated_by": "analysis-agent-v2",
            "model": "gpt-4o",
            "timestamp": "2024-04-15T14:22:00Z"
        }
    )
```

**Use cases**:
- AI-generated summaries
- Computed matrices
- Synthesized analyses

---

## Creating Citations

### Document Citations

```python
with CitationEngine() as engine:
    source = engine.add_doc_source("report.pdf", name="Annual Report")

    # Citation with verbatim quote
    result = engine.cite_doc(
        claim="The company achieved record profits in 2024",
        source_id=source.id,
        quote_context="Financial Results section shows record-breaking performance with profits exceeding $50M.",
        verbatim_quote="profits exceeding $50M",
        locator={
            "page": 12,
            "section": "Financial Results"
        }
    )

    # Citation with paraphrase
    result = engine.cite_doc(
        claim="Customer satisfaction improved significantly",
        source_id=source.id,
        quote_context="NPS scores rose from 42 to 67, indicating substantial improvement in customer sentiment.",
        locator={"page": 28},
        extraction_method="paraphrase"  # Not a direct quote
    )

    # Citation requiring inference
    result = engine.cite_doc(
        claim="The product strategy is working",
        source_id=source.id,
        quote_context="Revenue up 30%. Customer retention at 95%. Market share grew 5 points.",
        locator={"page": 5},
        extraction_method="inference",
        relevance_reasoning="Multiple positive metrics (revenue, retention, market share) together indicate successful strategy."
    )
```

### Web Citations

```python
with CitationEngine() as engine:
    source = engine.add_web_source(
        url="https://docs.python.org/3/library/asyncio.html",
        name="Python asyncio Documentation"
    )

    result = engine.cite_web(
        claim="asyncio is the standard library for async programming in Python",
        source_id=source.id,
        quote_context="asyncio is a library to write concurrent code using the async/await syntax.",
        locator={
            "url": "https://docs.python.org/3/library/asyncio.html",
            "section": "Introduction"
        }
    )
```

### Database Citations

```python
with CitationEngine() as engine:
    source = engine.add_db_source(
        identifier="sales.quarterly",
        name="Q1 Sales Data",
        content="Total sales: $1.2M across 3,400 transactions",
        query="SELECT SUM(amount), COUNT(*) FROM sales WHERE quarter = 'Q1'"
    )

    result = engine.cite_db(
        claim="Q1 had over 3000 sales transactions",
        source_id=source.id,
        quote_context="3,400 transactions",
        locator={
            "table": "sales",
            "query": "SELECT COUNT(*) FROM sales WHERE quarter = 'Q1'"
        },
        extraction_method="aggregation"
    )
```

### Custom Source Citations

```python
with CitationEngine() as engine:
    source = engine.add_custom_source(
        name="Market Analysis",
        content="Our market share is 23%, up from 18% last year.",
        description="Generated market analysis"
    )

    result = engine.cite_custom(
        claim="Market share grew by 5 percentage points",
        source_id=source.id,
        quote_context="market share is 23%, up from 18%",
        relevance_reasoning="23% - 18% = 5 percentage point increase"
    )
```

---

## Verification

### Understanding Verification Status

```python
from citation_engine import VerificationStatus

# After creating a citation
result = engine.cite_doc(...)

if result.verification_status == VerificationStatus.VERIFIED:
    print("Quote found and supports the claim")
elif result.verification_status == VerificationStatus.FAILED:
    print("Quote not found or doesn't support claim")
    print(f"Reason: {result.verification_notes}")
elif result.verification_status == VerificationStatus.PENDING:
    print("Verification not yet complete")
```

### Verification Scores

```python
result = engine.cite_doc(...)

# Similarity score: 0.0 to 1.0
print(f"Confidence: {result.similarity_score:.0%}")

# High confidence (> 0.8): Strong match
# Medium confidence (0.5-0.8): Acceptable match
# Low confidence (< 0.5): Weak match, review recommended
```

### Configuring Verification

```python
import os

# Require reasoning for low-confidence citations
os.environ["CITATION_REASONING_REQUIRED"] = "low"  # none, low, medium, high

# Use custom LLM endpoint
os.environ["CITATION_LLM_URL"] = "http://localhost:8080/v1"
os.environ["CITATION_LLM_MODEL"] = "mistral-7b"
```

---

## Citation Formatting

### Built-in Styles

```python
with CitationEngine() as engine:
    # ... create citation ...

    # Inline reference
    inline = engine.format_citation(result.citation_id, style="inline")
    # "[1] Annual Report 2024, p. 12"

    # Harvard style
    harvard = engine.format_citation(result.citation_id, style="harvard")
    # "Annual Report (2024) p. 12"

    # BibTeX format
    bibtex = engine.format_citation(result.citation_id, style="bibtex")
    # "@article{annual_report_2024, title={Annual Report}, ...}"
```

### Getting Full Citation Data

```python
# Retrieve complete citation object
citation = engine.get_citation(result.citation_id)

print(f"Claim: {citation.claim}")
print(f"Quote: {citation.quote_context}")
print(f"Source: {citation.source_id}")
print(f"Status: {citation.verification_status.value}")
print(f"Locator: {citation.locator}")
```

---

## Working with Citations

### Listing Sources

```python
with CitationEngine() as engine:
    # Get all registered sources
    sources = engine.list_sources()

    for source in sources:
        print(f"[{source.id}] {source.name} ({source.type.value})")
```

### Retrieving Sources

```python
# Get source by ID
source = engine.get_source(source_id)

print(f"Name: {source.name}")
print(f"Type: {source.type.value}")
print(f"Content length: {len(source.content)} chars")
print(f"Hash: {source.content_hash}")
```

### Superseding Citations

When a citation needs correction:

```python
# Original citation had an error
original = engine.cite_doc(
    claim="Revenue was $50M",  # Wrong!
    source_id=source.id,
    quote_context="Revenue reached $55M",
    locator={"page": 10}
)

# Create corrected citation that supersedes the original
corrected = engine.cite_doc(
    claim="Revenue was $55M",  # Correct
    source_id=source.id,
    quote_context="Revenue reached $55M",
    locator={"page": 10},
    supersedes=original.citation_id  # Links to original
)
```

---

## Multi-Agent Mode

For shared citation pools across multiple agents:

### Setup

```bash
# Start PostgreSQL
podman-compose up -d

# Set environment
export CITATION_DB_URL="postgresql://citation_user:citation_pass@localhost:5432/citations"
```

### Usage

```python
# Agent 1: Research Agent
with CitationEngine(mode="multi-agent") as engine:
    source = engine.add_doc_source("research.pdf", name="Research Paper")
    # Source ID is shared across agents

# Agent 2: Writing Agent (separate process)
with CitationEngine(mode="multi-agent") as engine:
    # Can access sources registered by Agent 1
    sources = engine.list_sources()
    result = engine.cite_doc(
        claim="The research shows...",
        source_id=sources[0].id,  # Use shared source
        quote_context="..."
    )
```

---

## LangChain Integration

Create tools for LangChain agents:

```python
from citation_engine import CitationEngine
from citation_engine.tool import create_citation_tools

# Create engine
engine = CitationEngine(mode="basic")

# Get LangChain tools
tools = create_citation_tools(engine)

# Tools available:
# - cite: Create a citation for a claim
# - register_source: Register a new source
# - list_sources: List all registered sources
# - get_citation_status: Check citation verification status

# Use with LangChain agent
from langchain.agents import initialize_agent, AgentType
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o")
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

response = agent.run("Summarize the key findings from the research paper and cite your sources.")
```

---

## Error Handling

### Common Exceptions

```python
from citation_engine import CitationEngine

with CitationEngine() as engine:

    # Source not found
    try:
        result = engine.cite_doc(
            claim="...",
            source_id="nonexistent-id",
            quote_context="..."
        )
    except ValueError as e:
        print(f"Invalid source: {e}")

    # File not found
    try:
        source = engine.add_doc_source("missing.pdf", name="Missing")
    except FileNotFoundError as e:
        print(f"File not found: {e}")

    # Web fetch failed
    try:
        source = engine.add_web_source(
            url="https://invalid-domain.invalid",
            name="Bad URL"
        )
    except ConnectionError as e:
        print(f"Failed to fetch: {e}")

    # Unsupported file type
    try:
        source = engine.add_doc_source("data.xlsx", name="Spreadsheet")
    except ValueError as e:
        print(f"Unsupported format: {e}")
```

### Verification Failures

```python
result = engine.cite_doc(...)

if result.verification_status == VerificationStatus.FAILED:
    # Citation was stored but verification failed
    print(f"Citation {result.citation_id} failed verification")
    print(f"Reason: {result.verification_notes}")

    # You may want to:
    # 1. Review the quote_context
    # 2. Check if the claim is supported
    # 3. Create a new citation with better evidence
```

---

## Best Practices

### 1. Register Sources Early

```python
# Good: Register all sources at the start
with CitationEngine() as engine:
    sources = {
        "report": engine.add_doc_source("report.pdf", name="Annual Report"),
        "data": engine.add_db_source("metrics", name="Metrics", content="..."),
    }

    # Now create citations referencing these sources
    result = engine.cite_doc(claim="...", source_id=sources["report"].id, ...)
```

### 2. Provide Rich Context

```python
# Good: Sufficient context for verification
result = engine.cite_doc(
    claim="Sales grew 20%",
    source_id=source.id,
    quote_context="The fiscal year 2024 saw remarkable growth with sales increasing by 20% compared to the previous year, driven primarily by expansion into new markets.",
    verbatim_quote="sales increasing by 20%",
    locator={"page": 15, "section": "Financial Overview"}
)

# Bad: Insufficient context
result = engine.cite_doc(
    claim="Sales grew 20%",
    source_id=source.id,
    quote_context="20%",  # Too short for reliable verification
    locator={"page": 15}
)
```

### 3. Use Appropriate Extraction Methods

```python
# Direct quote
extraction_method="verbatim"  # Default when verbatim_quote provided

# Reworded content
extraction_method="paraphrase"

# Derived from multiple facts
extraction_method="inference"  # Requires relevance_reasoning

# Computed from data
extraction_method="aggregation"  # For database sources
```

### 4. Handle Low-Confidence Citations

```python
result = engine.cite_doc(...)

if result.similarity_score < 0.5:
    print("Warning: Low confidence citation")
    print("Consider:")
    print("- Providing more context")
    print("- Using a more specific quote")
    print("- Adding relevance_reasoning")
```
